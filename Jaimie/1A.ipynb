{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Tweet Index  Label                                         Tweet text\n",
      "0            1      1  Sweet United Nations video. Just in time for C...\n",
      "1            2      1  @mrdahl87 We are rumored to have talked to Erv...\n",
      "2            3      1  Hey there! Nice to see you Minnesota/ND Winter...\n",
      "3            4      0                3 episodes left I'm dying over here\n",
      "4            5      2  \"I can't breathe!\" was chosen as the most nota...\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"SemEval2018-Task3/datasets/train/SemEval2018-T3-train-taskB.txt\", delimiter='\\t', quoting=csv.QUOTE_NONE, error_bad_lines=False)\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A) Linguistic analysis using spaCy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "num_words = 0\n",
    "num_tokens = 0\n",
    "total_word_length = 0 \n",
    "types_list=[]\n",
    "POS_frequencies_coarse = Counter()\n",
    "POS_frequencies_fine = Counter()\n",
    "\n",
    "token_count_dict = {}\n",
    "\n",
    "for index, tweet in dataset['Tweet text'].iteritems():\n",
    "    \n",
    "    doc = nlp(tweet)\n",
    "\n",
    "    for sentence in doc.sents:\n",
    "        POS_tags_coarse = []\n",
    "        POS_tags_fine = []\n",
    "\n",
    "        for token in sentence: \n",
    "            num_tokens += 1\n",
    "            if token.text not in types_list:\n",
    "                types_list.append(token.text)\n",
    "           \n",
    "            # Let's filter out punctuation\n",
    "            if not token.is_punct:\n",
    "                num_words += 1\n",
    "                total_word_length += len(token)\n",
    "                \n",
    "                POS_tags_coarse.append(token.pos_)\n",
    "                POS_tags_fine.append(token.tag_)\n",
    "\n",
    "                if token.text not in token_count_dict:\n",
    "                    token_count_dict[token.text] = {}\n",
    "                    token_count_dict[token.text]['count'] = 0\n",
    "                    token_count_dict[token.text]['POS_tag_fine'] = token.tag_\n",
    "                    token_count_dict[token.text]['POS_tag_coarse'] = token.pos_\n",
    "\n",
    "\n",
    "                token_count_dict[token.text]['count'] += 1\n",
    "                \n",
    "        POS_frequencies_coarse.update(POS_tags_coarse)\n",
    "        POS_frequencies_fine.update(POS_tags_fine)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens:  66518\n",
      "Number of types:  14957\n",
      "Number of words:  55221\n",
      "Average number of words per tweet:  14.402973395931143\n",
      "Average word length:  5.213415186251607\n"
     ]
    }
   ],
   "source": [
    "print('Number of tokens: ', num_tokens)\n",
    "print('Number of types: ', len(types_list))\n",
    "print('Number of words: ', num_words)\n",
    "\n",
    "print('Average number of words per tweet: ',num_words/len(dataset))\n",
    "print('Average word length: ', total_word_length/num_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequency_df = pd.DataFrame.from_dict(token_count_dict, orient='index').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NN', 9254), ('NNP', 5133), ('IN', 4728), ('DT', 3706), ('PRP', 3624), ('RB', 3519), ('JJ', 3446), ('VB', 2909), ('NNS', 2521), ('VBP', 2113)]\n"
     ]
    }
   ],
   "source": [
    "common_tags = POS_frequencies_fine.most_common(10)\n",
    "print(common_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['level_0', 'index', 'count', 'POS_tag_fine', 'POS_tag_coarse'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(word_frequency_df.reset_index().columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN\n",
      "     index  count POS_tag_fine POS_tag_coarse\n",
      "105    day    147           NN           NOUN\n",
      "6     time     94           NN           NOUN\n",
      "879  today     86           NN           NOUN\n",
      "index             http://t.co/E189iHBpZr\n",
      "count                                  1\n",
      "POS_tag_fine                          NN\n",
      "POS_tag_coarse                      NOUN\n",
      "Name: 14902, dtype: object\n",
      "NNP\n",
      "          index  count POS_tag_fine POS_tag_coarse\n",
      "8     Christmas     98          NNP          PROPN\n",
      "926          RT     51          NNP          PROPN\n",
      "2524        New     27          NNP          PROPN\n",
      "index             Motion\n",
      "count                  1\n",
      "POS_tag_fine         NNP\n",
      "POS_tag_coarse     PROPN\n",
      "Name: 14900, dtype: object\n",
      "IN\n",
      "   index  count POS_tag_fine POS_tag_coarse\n",
      "5     in    585           IN            ADP\n",
      "60    of    582           IN            ADP\n",
      "7    for    501           IN            ADP\n",
      "index             http://t.co/wsFo2Dlu7h\n",
      "count                                  1\n",
      "POS_tag_fine                          IN\n",
      "POS_tag_coarse                       ADP\n",
      "Name: 14869, dtype: object\n",
      "DT\n",
      "   index  count POS_tag_fine POS_tag_coarse\n",
      "24   the   1296           DT            DET\n",
      "67     a    991           DT            DET\n",
      "30  that    418           DT            DET\n",
      "index             EVERY\n",
      "count                 1\n",
      "POS_tag_fine         DT\n",
      "POS_tag_coarse      DET\n",
      "Name: 14877, dtype: object\n",
      "PRP\n",
      "    index  count POS_tag_fine POS_tag_coarse\n",
      "46      I   1247          PRP           PRON\n",
      "38    you    572          PRP           PRON\n",
      "300    it    435          PRP           PRON\n",
      "index             http://t.co/gkwKJvTrku\n",
      "count                                  1\n",
      "POS_tag_fine                         PRP\n",
      "POS_tag_coarse                      PRON\n",
      "Name: 13850, dtype: object\n",
      "RB\n",
      "    index  count POS_tag_fine POS_tag_coarse\n",
      "52    n't    376           RB           PART\n",
      "249    so    226           RB            ADV\n",
      "121   not    211           RB           PART\n",
      "index             myfairdaily\n",
      "count                       1\n",
      "POS_tag_fine               RB\n",
      "POS_tag_coarse            ADV\n",
      "Name: 14870, dtype: object\n",
      "JJ\n",
      "     index  count POS_tag_fine POS_tag_coarse\n",
      "177  great    104           JJ            ADJ\n",
      "856   good     84           JJ            ADJ\n",
      "902    fun     73           JJ            ADJ\n",
      "index             nosurprisethere\n",
      "count                           1\n",
      "POS_tag_fine                   JJ\n",
      "POS_tag_coarse                ADJ\n",
      "Name: 14896, dtype: object\n",
      "VB\n",
      "    index  count POS_tag_fine POS_tag_coarse\n",
      "102    be    265           VB           VERB\n",
      "18   have    239           VB            AUX\n",
      "141   get    153           VB           VERB\n",
      "index             Want\n",
      "count                1\n",
      "POS_tag_fine        VB\n",
      "POS_tag_coarse    VERB\n",
      "Name: 14903, dtype: object\n",
      "NNS\n",
      "      index  count POS_tag_fine POS_tag_coarse\n",
      "573  people    104          NNS           NOUN\n",
      "150   hours     38          NNS           NOUN\n",
      "371  Thanks     36          NNS           NOUN\n",
      "index             Hummingbirds\n",
      "count                        1\n",
      "POS_tag_fine               NNS\n",
      "POS_tag_coarse            NOUN\n",
      "Name: 14897, dtype: object\n",
      "VBP\n",
      "    index  count POS_tag_fine POS_tag_coarse\n",
      "107    do    246          VBP            AUX\n",
      "15    are    224          VBP            AUX\n",
      "47     'm    204          VBP            AUX\n",
      "index             whistle\n",
      "count                   1\n",
      "POS_tag_fine          VBP\n",
      "POS_tag_coarse       VERB\n",
      "Name: 14798, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for tag in list(zip(*common_tags))[0]:\n",
    "    print(tag)\n",
    "    df_tag = word_frequency_df.loc[word_frequency_df['POS_tag_fine']==tag].sort_values(by='count', ascending=False)\n",
    "    print(df_tag.iloc[:3])\n",
    "    print(df_tag.iloc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, tweet in dataset['Tweet text'].iloc[:100].iteritems():\n",
    "    doc = nlp(tweet)\n",
    "\n",
    "    for sentence in doc.sents:\n",
    "        for token in sentence: \n",
    "            if token.text != token.lemma_:\n",
    "                print(token.text, token.lemma_, sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NER_frequencies = Counter()\n",
    "\n",
    "for index, tweet in dataset['Tweet text'].iteritems():\n",
    "    doc = nlp(tweet)\n",
    "\n",
    "    NER_list = []\n",
    "    for ent in doc.ents:\n",
    "        NER_list.append(ent.label_)\n",
    "    \n",
    "    NER_frequencies.update(NER_list)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(NER_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of named entities: ', len(NER_frequencies))\n",
    "print('Number of different entity labels: ', sum(NER_frequencies.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "for index, tweet in dataset['Tweet text'].iloc[:3].iteritems():\n",
    "    doc=nlp(tweet)\n",
    "    displacy.render(doc, jupyter=True, style='ent')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLPtech",
   "language": "python",
   "name": "nlptech"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
